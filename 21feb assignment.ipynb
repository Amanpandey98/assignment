{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12779cb3-55f6-40bd-8628-698314002a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16d994-cc2c-4d9c-9bef-91bf8b312501",
   "metadata": {},
   "outputs": [],
   "source": [
    "Web scraping, also known as data scraping or web harvesting, is the process of extracting data from websites automatically using software or a web scraper tool. It involves analyzing the structure of a website and extracting relevant information in a structured format such as CSV, JSON, or XML.\n",
    "Three areas where web scraping is commonly used to get data are:\n",
    "\n",
    "1.E-commerce: Web scraping is used in e-commerce to gather data on product prices, reviews, and availability from different online stores.\n",
    "\n",
    "2.Social Media: Web scraping is used to gather data from social media platforms such as Twitter and Instagram to monitor trends, track user behavior, and analyze sentiment.\n",
    "\n",
    "3.Real Estate: Real estate companies use web scraping to gather data on property prices, availability, and location from various websites to help them make informed decisions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cad9d0-57a4-4db5-9e3e-33e300e990c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc206c-a47a-4a10-82c7-2e3d394c2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are various methods used for web scraping. Some of the most common methods are:\n",
    "\n",
    "1.Parsing HTML: Parsing HTML is the most common method used for web scraping. It involves analyzing the HTML structure of a web page to extract relevant information using programming languages like Python, Ruby, or JavaScript.\n",
    "\n",
    "2.Web Scraping Tools: Web scraping tools or software are designed to automate the web scraping process. These tools use advanced algorithms to extract data from web pages and store it in a structured format. Some popular web scraping tools include Scrapy, Beautiful Soup, and Selenium.\n",
    "\n",
    "3.APIs: APIs (Application Programming Interfaces) provide a structured way for applications to interact with websites and access data. Some websites offer APIs that allow developers to access and extract data from their sites. However, some websites may charge for API access or limit the amount of data that can be accessed.\n",
    "\n",
    "4.Web Scraping Services: There are also web scraping services that specialize in providing data extraction solutions to businesses. These services can offer customized web scraping solutions that can be tailored to specific needs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4405aa7-cd42-4caf-9db6-26f8329abcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00bdff-14ef-4225-8292-e9eb6fb14c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beautiful Soup is a Python library used for web scraping purposes. It is a popular library used for parsing HTML and XML documents, and it provides a simple interface for navigating and searching the parsed documents. Beautiful Soup can be used to extract data from HTML and XML files, making it a valuable tool for web scraping.\n",
    "\n",
    "Beautiful Soup is used for a variety of reasons, including:\n",
    "\n",
    "1.Extracting Data: Beautiful Soup makes it easy to extract specific data from HTML and XML documents, such as text, links, and images.\n",
    "\n",
    "2.Parsing HTML Documents: Beautiful Soup provides a simple interface for parsing HTML and XML documents, allowing users to navigate and search the documents with ease.\n",
    "\n",
    "3.Data Cleaning: Beautiful Soup can be used to clean up HTML and XML documents, removing unnecessary tags and formatting to make the data easier to read and work with.\n",
    "\n",
    "4.Web Scraping: Beautiful Soup is commonly used for web scraping purposes, as it makes it easy to extract data from websites and store it in a structured format for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690d2d3-3bfa-473b-b669-03327c8e88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785cdb83-6b0c-4b07-aba9-a716a31c65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flask is a lightweight web application framework that is commonly used for building web applications and APIs using Python. Flask is often used for web scraping projects because it provides a simple, yet powerful way to build web applications that can interact with the data being scraped.\n",
    "In a web scraping project, Flask can be used to build a web application that interacts with the scraped data, allowing users to view and manipulate the data in a user-friendly way. For example, a Flask application can be used to display the scraped data in a table or graph, or to allow users to filter and search the data based on specific criteria.\n",
    "Flask can also be used to create APIs that allow other applications to access the scraped data, making it easier to integrate the data into other applications and services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e177fc9-6083-413c-a3e5-2cac14b9ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dccee45-c58b-4807-9511-cad99a4178d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Amazon EC2: Amazon Elastic Compute Cloud (EC2) is a scalable cloud computing service that provides resizable computing capacity in the cloud. EC2 instances can be used to run web scraping scripts, allowing users to easily scale up or down based on the amount of data being scraped.\n",
    "\n",
    "2.Amazon S3: Amazon Simple Storage Service (S3) is a cloud storage service that can be used to store the scraped data. S3 provides scalable and durable object storage that can be accessed from anywhere with an internet connection.\n",
    "\n",
    "3.Amazon Lambda: AWS Lambda is a serverless computing service that allows users to run code without the need to manage servers. Lambda can be used to run web scraping scripts on a scheduled basis, making it easy to automate the scraping process.\n",
    "\n",
    "4.Amazon SQS: Amazon Simple Queue Service (SQS) is a message queuing service that can be used to manage the flow of data during the scraping process. SQS can be used to decouple the scraping process from downstream processing, allowing the scraping process to run independently and at its own pace.\n",
    "\n",
    "5.Amazon Glue: AWS Glue is a fully managed extract, transform, and load (ETL) service that can be used to prepare and transform the scraped data for downstream processing. Glue can be used to clean and normalize the data, making it easier to analyze and work with.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
