{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df8e27a5-efd6-4a6d-a863-d1af6e05520b",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367a4d8-be50-43a8-a405-4daff821eddd",
   "metadata": {},
   "source": [
    "Missing values refer to the absence of data for one or more variables in a dataset. This can occur due to various reasons, such as measurement errors, data corruption, or intentional data omission. Missing values can have a significant impact on the analysis and modeling of data, as they can lead to biased or inaccurate results if not handled appropriately.\n",
    "\n",
    "It is essential to handle missing values because they can cause problems such as:\n",
    "\n",
    "Biased results: If missing values are not handled, they can lead to biased results as the analysis would be based on incomplete data.\n",
    "\n",
    "Reduced accuracy: Missing values can reduce the accuracy of statistical models because they can cause the model to estimate parameters that are not representative of the true population.\n",
    "\n",
    "Reduced sample size: Missing values can reduce the sample size, leading to a loss of statistical power and making it harder to detect significant relationships.\n",
    "\n",
    "Some of the algorithms that are not affected by missing values include:\n",
    "\n",
    "1.Decision trees: Decision trees are not affected by missing values because they can handle them by treating missing values as a separate category or by using surrogate splits.\n",
    "\n",
    "2.Random Forests: Random forests can handle missing values by imputing them with the median or mean value of the variable or using a surrogate variable.\n",
    "\n",
    "3.Support Vector Machines (SVM): SVMs can handle missing values by ignoring the missing data points during the model training process.\n",
    "\n",
    "4.K-Nearest Neighbors (KNN): KNN can handle missing values by imputing them with the mean or median value of the nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc3d08-9803-4f7c-a2b2-e83284297450",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca0f50-3a6e-472f-a815-a5152493b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Deletion:\n",
    "Deletion is a technique that involves removing the rows or columns with missing values from the dataset. This technique is useful when the amount of missing data is small, and the remaining data is still sufficient for analysis.\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset with missing values\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_drop = df.dropna()\n",
    "df_drop = df.dropna()\n",
    "\n",
    "2.Imputation:\n",
    "Imputation is a technique that involves filling in the missing values with estimated values. This technique can be done using various methods such as mean imputation, median imputation, mode imputation, or regression imputation.\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset with missing values\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Fill missing values with mean\n",
    "df_impute_mean = df.fillna(df.mean())\n",
    "\n",
    "3.Interpolation:\n",
    "Interpolation is a technique that involves estimating missing values based on the values of other data points in the same dataset. This technique can be done using various methods such as linear interpolation, spline interpolation, or K-nearest neighbor interpolation.\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset with missing values\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Interpolate missing values using linear interpolation\n",
    "df_interpolate = df.interpolate()\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset with missing values\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Interpolate missing values using linear interpolation\n",
    "df_interpolate = df.interpolate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ada21-7e12-482a-96d3-fee63b4c7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1a404-149c-4bf2-b5a5-6ee15d775ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imbalanced data refers to a situation where the distribution of classes in a dataset is not equal, i.e., one class has significantly fewer samples than the other(s). In other words, the number of samples in each class is not proportional. For instance, if a binary classification dataset has 90% positive class samples and only 10% negative class samples, then the data is imbalanced.\n",
    "\n",
    "If imbalanced data is not handled, it can cause several problems, including:\n",
    "\n",
    "1.Biased models: Machine learning models trained on imbalanced data can become biased towards the majority class, leading to poor performance on the minority class. The models may have high accuracy but low precision, recall, and F1-score on the minority class.\n",
    "\n",
    "2.Poor generalization: Imbalanced data can lead to models that are overfitted to the majority class and cannot generalize well to new data or data with a different class distribution.\n",
    "\n",
    "3.Incorrect ranking: In some applications, such as fraud detection or disease diagnosis, the cost of misclassifying the minority class samples is much higher than that of the majority class. If imbalanced data is not handled, the model may incorrectly rank the minority class samples, leading to significant financial or health-related losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5da2a0-c82e-4cf5-89a1-2ea3571f0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1c945-8062-4ae6-aa9e-0733737e7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Upsampling and downsampling are techniques used to handle imbalanced data.\n",
    "\n",
    "Upsampling is a technique used to increase the number of samples in the minority class to balance the distribution of classes in the dataset. This can be done by duplicating existing samples or creating new synthetic samples using various algorithms. Upsampling is typically used when the number of samples in the minority class is too small compared to the majority class.\n",
    "\n",
    "For example, suppose we have a binary classification dataset with 1000 samples, out of which only 100 belong to the minority class. In this case, we can use upsampling to increase the number of samples in the minority class to balance the dataset.\n",
    "\n",
    "Downsampling, on the other hand, is a technique used to reduce the number of samples in the majority class to balance the distribution of classes in the dataset. This can be done by randomly removing samples from the majority class until the distribution between the classes becomes more balanced. Downsampling is typically used when the number of samples in the majority class is significantly larger than the minority class.\n",
    "\n",
    "For example, suppose we have a binary classification dataset with 1000 samples, out of which 900 belong to the majority class. In this case, we can use downsampling to reduce the number of samples in the majority class to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaccbc0-37d6-45be-91c1-ae41975b1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae31967-a9ca-4038-8253-0f1b3ec18aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data augmentation is a technique used in machine learning to artificially increase the size of a dataset by generating new samples from existing ones. The new samples are created by applying various transformations to the original data, such as rotation, scaling, flipping, and shifting.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a popular data augmentation technique used to handle imbalanced data. SMOTE generates synthetic samples for the minority class by interpolating between existing minority class samples. The algorithm works by selecting a sample from the minority class and then selecting k nearest neighbors from the same class. A new synthetic sample is then created by interpolating between the selected sample and one of its k nearest neighbors. The process is repeated until the desired number of synthetic samples is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ed26f-d386-4b07-9160-54ecf2699dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bdf95-9969-4198-a046-b3fcd5de8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers are data points in a dataset that are significantly different from the majority of the other data points. These data points are usually much higher or much lower than the average value of the dataset and can affect the statistical analysis and machine learning algorithms trained on the data.\n",
    "\n",
    "It is essential to handle outliers in a dataset for several reasons:\n",
    "\n",
    "1.Outliers can significantly affect the mean and standard deviation of a dataset, leading to biased statistical analysis and misleading results.\n",
    "\n",
    "2.Outliers can have a disproportionate impact on machine learning algorithms that are sensitive to the scale and distribution of the data, such as linear regression and k-nearest neighbors.\n",
    "\n",
    "3.Outliers can also affect the performance of clustering algorithms and lead to the creation of suboptimal clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e1954-d48a-4bef-91e3-5c09feb8eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b924d-4b04-4621-8c17-fbf9ec255556",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imputation: This technique involves replacing missing values with estimated values based on the other available data points. There are several imputation methods such as mean imputation, median imputation, and mode imputation. Mean imputation replaces missing values with the mean of the available data points, while median imputation replaces missing values with the median of the available data points. Mode imputation replaces missing values with the mode of the available data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb8557-a7dd-483d-ba6d-73a660c926f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64908e04-5c0a-42be-8bc9-1c6fd6fef5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Determining whether the missing data is missing at random (MAR) or missing not at random (MNAR) is important in handling missing data because the approach used for imputing missing data depends on the pattern of missing data. Here are some strategies to determine the pattern of missing data:\n",
    "1.Visual inspection\n",
    "2.Statistical tests\n",
    "3.Imputation and comparison\n",
    "4.Domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392028b-1b67-401f-844b-5f88ea381edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18bf3f-cf33-47c3-8728-1d0483645128",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dealing with imbalanced datasets in medical diagnosis is a common problem. Here are some strategies to evaluate the performance of machine learning models on imbalanced datasets:\n",
    "\n",
    "1.Confusion matrix\n",
    "2.Precision-recall curve\n",
    "3.ROC curve\n",
    "4.Resampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9eaec1-fc13-41de-ab1b-1c5aa90dde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da571a40-6e32-4fc7-9651-8bab995c6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "To balance an unbalanced dataset, we can use several techniques such as oversampling the minority class, undersampling the majority class, or a combination of both. Here are some methods to down-sample the majority class:\n",
    "\n",
    "1.Random undersampling: Randomly selecting a subset of the majority class to match the size of the minority class. This method is simple and quick, but it can lead to a loss of information.\n",
    "\n",
    "2.Cluster centroids undersampling: Using clustering algorithms to group the majority class and selecting the centroids of each cluster as representatives. This method preserves the information of the original data and can lead to better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e478c-5265-4993-a9fb-8b39d3925367",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d08e63-2349-4022-bc22-a2873f14e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "To balance an unbalanced dataset with a low percentage of occurrences, we can use several techniques such as oversampling the minority class, undersampling the majority class, or a combination of both. Here are some methods to up-sample the minority class:\n",
    "\n",
    "Random oversampling: Randomly duplicating instances from the minority class to increase its size. This method is simple and quick, but it can lead to overfitting.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique): Creating synthetic instances of the minority class by interpolating between existing instances. This method is more sophisticated than random oversampling and can generate more representative synthetic instances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
