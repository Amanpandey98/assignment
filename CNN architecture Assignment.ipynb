{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64a228e-a6b3-4993-bd22-e7616ba827b6",
   "metadata": {},
   "source": [
    "## TOPIC: Understanding Pooling and Padding in CNN\n",
    "1. describe the purpose and benefit of pooling in CNN\n",
    "\n",
    "ans:Pooling, also known as subsampling or downsampling, is a technique used in Convolutional Neural Networks (CNNs) to reduce the spatial dimensions of feature maps while retaining the important information. The primary purpose of pooling is to decrease the computational complexity of the network and to extract significant features from the input data. There are two common types of pooling operations: Max Pooling and Average Pooling.\n",
    "\n",
    "* Max Pooling:\n",
    "In max pooling, for each region of the feature map, the maximum value is selected and retained while discarding the other values. This operation helps to capture the most prominent features within a region and reduce the sensitivity of the network to small variations.\n",
    "\n",
    "* Average Pooling:\n",
    "In average pooling, the average value of the elements in a region of the feature map is calculated and used as the pooled value. This operation can help in reducing the noise in the feature map and providing a smoothed representation.\n",
    "\n",
    "- The benefits and purposes of pooling in CNNs are as follows:\n",
    "\n",
    "- Dimension Reduction: Pooling reduces the spatial dimensions of the feature maps, which in turn reduces the number of parameters in the subsequent layers. This helps in decreasing the computational load and memory requirements of the network.\n",
    "\n",
    "- Computationally Efficient: Pooling reduces the number of operations needed in the network, making the training process faster and more efficient. This is particularly beneficial when dealing with large and complex datasets.\n",
    "\n",
    " # 2. Explain the difference between min pooling and max pooling\n",
    "\n",
    "* Max Pooling:\n",
    "In max pooling, for each region of the feature map, the maximum value within that region is selected and retained as the pooled value. The idea behind max pooling is to capture the most prominent feature present in a particular region. This operation helps in achieving translation invariance by focusing on the most significant features while discarding less relevant information.\n",
    "\n",
    "- Advantages of Max Pooling:\n",
    "\n",
    "Captures dominant features in a region.\n",
    "Helps in achieving invariance to small translations and variations.\n",
    "Enhances the network's ability to recognize key patterns.\n",
    "\n",
    "- Disadvantages of Max Pooling:\n",
    "\n",
    "Ignores less prominent features within a region.\n",
    "Might lead to information loss in cases where multiple significant features exist in the same region.\n",
    "\n",
    "* Min Pooling:\n",
    "Min pooling is less common than max pooling and involves selecting the minimum value within a region of the feature map as the pooled value. The rationale behind min pooling is similar to max pooling but with a focus on capturing the least prominent feature or the minimum value within a region.\n",
    "\n",
    "- Advantages of Min Pooling:\n",
    "\n",
    "Could potentially capture unique, less prominent features in a region.\n",
    "Might provide a different perspective on the data compared to max pooling.\n",
    "Disadvantages of Min Pooling:\n",
    "\n",
    "More susceptible to noise and variations in the data.\n",
    "May not perform as well as max pooling in capturing dominant patterns.\n",
    "\n",
    "# 3.Discuss the concept of padding in CNN and its significance.\n",
    "\n",
    "Padding is a technique used in Convolutional Neural Networks (CNNs) to control the spatial dimensions of feature maps as they pass through convolutional layers. It involves adding extra pixels or values around the borders of the input data before performing convolution. The added values are typically zeros, hence this technique is often referred to as \"zero-padding.\"\n",
    "\n",
    "Padding serves several significant purposes in CNNs:\n",
    "\n",
    "- Preserving Spatial Dimensions: When a convolutional operation is applied to an input image without padding, the size of the output feature map is reduced due to the way the convolution \"slides\" over the input. This reduction in size can lead to a gradual loss of spatial information, especially in deeper layers of the network. By using padding, you can ensure that the output feature map maintains the same spatial dimensions as the input, which can be crucial for accurate localization and maintaining details.\n",
    "\n",
    "- There are two main types of padding:\n",
    "\n",
    "Valid Padding (No Padding): In valid padding, no padding is added, and the convolution operation is applied only to the valid parts of the input. This leads to a reduction in the size of the output feature map.\n",
    "\n",
    "Same Padding: In same padding, padding is added such that the output feature map maintains the same spatial dimensions as the input. The amount of padding is determined by the size of the convolutional kernel. This ensures that the center of the kernel aligns with the center of the input region.\n",
    "\n",
    "# 4.Compare and contrast zero-padding and valid-padding in terms of their effects on the output featuce map size.\n",
    "\n",
    "- Zero-Padding:\n",
    "\n",
    "Effect on Output Size: Zero-padding increases the size of the input by adding extra rows and columns of zeros around the borders. As a result, the output feature map will have larger dimensions compared to the input.\n",
    "\n",
    "Preservation of Spatial Dimensions: Zero-padding is commonly used to preserve the spatial dimensions of the input. The added zeros ensure that the convolution operation is centered on the input pixels, allowing the output to maintain the same size as the input.\n",
    "\n",
    "Mitigation of Border Effects: Zero-padding helps mitigate the loss of information from the edges of the input during convolution. By providing a \"buffer\" of zeros around the input, the convolutional kernel can properly capture information from the borders.\n",
    "\n",
    "- Valid-Padding (No Padding):\n",
    "\n",
    "Effect on Output Size: Valid-padding, also known as no padding, does not add any additional rows or columns around the input. As a result, the convolution operation is only applied to the \"valid\" parts of the input, which reduces the size of the output feature map compared to the input.\n",
    "\n",
    "Preservation of Spatial Dimensions: Valid-padding does not aim to preserve the spatial dimensions. Instead, it leads to a reduction in the size of the output feature map, which can result in a loss of spatial information.\n",
    "\n",
    "Mitigation of Border Effects: Valid-padding does not provide any buffer for the convolutional kernel to capture information from the borders of the input. This can lead to a loss of information from the edges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d75c23-eda5-43f2-87d6-8b88529bbe84",
   "metadata": {},
   "source": [
    "## TOPIC: Exploring LeNet\n",
    "# 1. Provide a brief overview of LeNet-5 architecture.\n",
    "\n",
    "LeNet-5 is a pioneering convolutional neural network (CNN) architecture developed by Yann LeCun and his colleagues in the 1990s. It played a crucial role in popularizing the concept of deep learning and convolutional networks, particularly for image recognition tasks. LeNet-5 was designed primarily for handwritten digit recognition and is considered one of the early successes in the field of deep learning. Here's an overview of the LeNet-5 architecture:\n",
    "\n",
    "- Architecture Overview:\n",
    "\n",
    "Input Layer: LeNet-5 takes as input grayscale images of size 32x32 pixels. The images are represented as 2D arrays of pixel values.\n",
    "\n",
    "Convolutional Layers: LeNet-5 consists of two sets of convolutional and pooling layers. Each convolutional layer is followed by a pooling layer. The convolutional layers use small filters to perform convolutions on the input images, extracting local features.\n",
    "\n",
    "Activation Function: LeNet-5 uses the sigmoid activation function for the neurons in its convolutional and fully connected layers. While modern architectures often use rectified linear units (ReLU), sigmoid was commonly used during the time of LeNet-5's development.\n",
    "\n",
    "Pooling Layers: The pooling layers in LeNet-5 perform average pooling. They reduce the spatial dimensions of the feature maps, helping in capturing important features while decreasing the computational complexity of the network.\n",
    "\n",
    "Fully Connected Layers: After the convolutional and pooling layers, the feature maps are flattened and passed through fully connected layers. These layers learn higher-level representations by combining features from different regions of the input.\n",
    "\n",
    "Output Layer: The final fully connected layer has 10 neurons, corresponding to the 10 possible classes (digits 0 through 9). The output of these neurons represents the network's prediction probabilities for each class.\n",
    "\n",
    "# 2.Describe the key components of LeNet-5 and their respective purposes.\n",
    "\n",
    "LeNet-5 is a convolutional neural network (CNN) architecture designed for handwritten digit recognition. It consists of several key components that work together to process input images and make predictions. Here are the key components of LeNet-5 and their respective purposes:\n",
    "\n",
    "- Input Layer:\n",
    "\n",
    "Purpose: The input layer receives the grayscale images of handwritten digits as input. Each image is represented as a 32x32 pixel matrix of pixel values.\n",
    "Convolutional Layers:\n",
    "\n",
    "Purpose: The convolutional layers perform feature extraction by applying convolutional filters (kernels) to the input images. These filters learn to detect different local patterns, such as edges and corners.\n",
    "Details: LeNet-5 has two convolutional layers. The first layer has six 5x5 filters, and the second layer has sixteen 5x5 filters.\n",
    "Activation: LeNet-5 uses the sigmoid activation function in the convolutional layers.\n",
    "Average Pooling Layers:\n",
    "\n",
    "Purpose: The pooling layers reduce the spatial dimensions of the feature maps generated by the convolutional layers. They help in retaining the most important information while reducing computational complexity.\n",
    "Details: LeNet-5 uses average pooling with 2x2 pooling windows and a stride of 2.\n",
    "Fully Connected Layers:\n",
    "\n",
    "Purpose: The fully connected layers combine the features extracted by the convolutional and pooling layers to make final predictions.\n",
    "Details: LeNet-5 has two fully connected layers. The first fully connected layer has 120 neurons, and the second has 84 neurons.\n",
    "Activation: The sigmoid activation function is used in the fully connected layers.\n",
    "Output Layer:\n",
    "\n",
    "Purpose: The output layer makes predictions based on the features learned by the previous layers. In the case of LeNet-5, it predicts the digit class (0-9) corresponding to the input image.\n",
    "Details: The output layer has 10 neurons, each representing a possible digit class.\n",
    "Activation: LeNet-5 uses the sigmoid activation function here as well, although modern architectures typically use softmax for multi-class classification.\n",
    "\n",
    "# 3.Discuss the advantages and limitation of LeNet-5 in the context of Image Classification task.\n",
    "\n",
    "# Advantages of LeNet-5 for Image Classification:\n",
    "\n",
    "* Pioneering Architecture: LeNet-5 was one of the first successful CNN architectures, setting the foundation for modern deep learning in image classification. It demonstrated the effectiveness of hierarchical feature extraction, which remains a fundamental concept in convolutional neural networks.\n",
    "\n",
    "* Local Feature Extraction: The convolutional layers in LeNet-5 focus on local feature extraction, making it well-suited for tasks where recognizing local patterns, edges, and textures is important. This is particularly beneficial for digit recognition and similar tasks.\n",
    "\n",
    "* Spatial Hierarchies: LeNet-5 uses a combination of convolutional and pooling layers to create spatial hierarchies of features. This helps the network capture progressively higher-level features as it moves deeper into the architecture.\n",
    "\n",
    "# Limitations of LeNet-5 for Image Classification:\n",
    "\n",
    "* Limited Capacity: LeNet-5 has a relatively shallow architecture compared to modern CNNs. This limits its ability to capture complex and high-level features present in more intricate datasets.\n",
    "\n",
    "* Small Input Size: LeNet-5 was designed for 32x32 pixel grayscale images, which restricts its applicability to datasets with small image sizes. Modern image classification tasks often involve larger and more detailed images.\n",
    "\n",
    "* Sigmoid Activation: LeNet-5 uses the sigmoid activation function, which can suffer from the vanishing gradient problem and slower convergence compared to modern activation functions like ReLU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1049d56-935e-4f3e-8ce0-2f04f7b4eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.57.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 16:02:06.028936: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 16:02:06.448604: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-22 16:02:06.451737: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 16:02:08.157626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 14, 14, 6)         0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 5, 5, 16)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62006 (242.21 KB)\n",
      "Trainable params: 62006 (242.21 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#4.Implement LeNet-5 using a deep learning framework of your choice and train it on a publicly available dataset.Evaluates performance and its insights.\n",
    "!pip install tensorflow\n",
    "#importing necesaary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras \n",
    "from keras.layers import Conv2D,AveragePooling2D,Flatten,Dense\n",
    "from keras.models import Sequential\n",
    "#loading cifar-10 dataset\n",
    "(X_train,y_train),(X_test,y_test)=keras.datasets.cifar10.load_data()\n",
    "#normalize ixel values between 0 and 1 by dividing it by 255\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "#convert labels to one hot encoding\n",
    "y_train=keras.utils.to_categorical(y_train,10)#num_classes=10\n",
    "y_test=keras.utils.to_categorical(y_test,10)\n",
    "#Building the model architecture\n",
    "model=Sequential()\n",
    "model.add(Conv2D(6,kernel_size=(5,5),padding='valid',activation='tanh',input_shape=(32,32,3)))#padding=valid means=0,\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16,kernel_size=(5,5),padding='valid',activation='tanh'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(120,activation='tanh'))\n",
    "model.add(Dense(84,activation='tanh'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='SGD',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=128,epochs=2,verbose=1,validation_data=(X_test,y_test))  \n",
    "\n",
    "#cant proceed further because the kernel dies whenever i am compiling and fitting the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a848721-3733-4416-a98f-27295e0d353f",
   "metadata": {},
   "source": [
    "## TOPIC: Analyzing AlexNet\\\n",
    "# 1. Present an overview of the AlexNet architecture.\n",
    "\n",
    "AlexNet is a seminal convolutional neural network (CNN) architecture that played a pivotal role in advancing the field of deep learning and computer vision. It was designed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012. Here's an overview of the AlexNet architecture:\n",
    "\n",
    "Architecture Overview:\n",
    "\n",
    "Input Layer:\n",
    "\n",
    "1. Purpose: The input layer receives RGB images of varying sizes (227x227 pixels) as input.\n",
    "Convolutional Layers:\n",
    "\n",
    "Purpose: The convolutional layers perform feature extraction by applying convolutional filters to the input images. These filters learn to detect local patterns, textures, and edges.\n",
    "Details: AlexNet has five convolutional layers, with varying filter sizes (11x11, 5x5, and 3x3). The first two convolutional layers use a stride of 4, which reduces the spatial dimensions of the feature maps.\n",
    "ReLU Activation:\n",
    "\n",
    "2. Purpose: Rectified Linear Unit (ReLU) activation functions introduce non-linearity and sparsity into the network, allowing it to learn complex relationships in the data.\n",
    "Details: ReLU activation is applied after each convolutional and fully connected layer.\n",
    "Max Pooling Layers:\n",
    "\n",
    "3. Purpose: The max pooling layers downsample the feature maps, reducing their spatial dimensions and helping to capture important features while decreasing computational complexity.\n",
    "Details: AlexNet uses max pooling with a window size of 3x3 and a stride of 2.\n",
    "Normalization Layers:\n",
    "\n",
    "4. Purpose: Local Response Normalization (LRN) layers were used to enhance the contrast between features in the early layers. They are less commonly used in modern architectures.\n",
    "Details: LRN was applied after some of the convolutional layers.\n",
    "Fully Connected Layers:\n",
    "\n",
    "5. Purpose: The fully connected layers combine the features learned by the convolutional layers and make final predictions.\n",
    "Details: AlexNet has three fully connected layers. The first two have 4096 neurons each, and the last one has 1000 neurons (corresponding to the ImageNet class labels).\n",
    "Dropout:\n",
    "\n",
    "6. Purpose: Dropout is used during training to prevent overfitting. It randomly drops a fraction of neurons during each training iteration, forcing the network to learn more robust features.\n",
    "Details: Dropout is applied after the fully connected layers.\n",
    "Output Layer:\n",
    "\n",
    "7. Purpose: The output layer produces predictions for the ImageNet classes (1000 classes in total).\n",
    "Activation: The softmax activation function is used to convert the network's output into class probabilities.\n",
    "\n",
    "# 2.  Explain the architectural innovations introduced in AlexNet that contributed to its breakthrough performance\n",
    "\n",
    "ReLU Activation Function:\n",
    "\n",
    "* Rectified Linear Unit (ReLU) activation was a fundamental departure from the traditional sigmoid or hyperbolic tangent activation functions. ReLU replaces negative values with zero and allows positive values to pass through unchanged.\n",
    "Advantages: ReLU introduces non-linearity, which is crucial for learning complex relationships in data. It also mitigates the vanishing gradient problem, enabling faster and more stable training.\n",
    "Impact: ReLU greatly accelerated training convergence and enabled the training of much deeper networks.\n",
    "\n",
    "* Large Convolutional Kernels:\n",
    "\n",
    "AlexNet used larger convolutional kernel sizes, such as 11x11 and 5x5, compared to the smaller sizes used in earlier architectures.\n",
    "Advantages: Larger kernels allowed the network to capture more complex and higher-level features in the early layers. They were particularly effective in capturing global patterns.\n",
    "\n",
    "* Deep Architecture:\n",
    " AlexNet consisted of eight layers with learnable parameters, including five convolutional layers and three fully connected layers.\n",
    "Advantages: The depth of the network allowed it to learn intricate and abstract features from the data, enabling it to recognize complex patterns in images.\n",
    "\n",
    "* Overlapping Pooling:\n",
    "\n",
    "AlexNet employed overlapping max pooling layers with a window size of 3x3 and a stride of 2.\n",
    "Advantages: Overlapping pooling helped reduce the risk of information loss, as adjacent pooling regions overlapped by a stride of 1. This contributed to better feature preservation.\n",
    "Local Response Normalization (LRN):\n",
    "\n",
    "* Dropout Regularization:\n",
    "\n",
    "Dropout was applied after the fully connected layers during training.\n",
    "Purpose: Dropout randomly drops a fraction of neurons during each training iteration, preventing overfitting and promoting the learning of more robust features.\n",
    "Impact: Dropout played a role in improving the network's generalization capability.\n",
    "\n",
    "# 3. Discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet.\n",
    "\n",
    "* Convolutional Layers:\n",
    "Convolutional layers perform the crucial task of feature extraction from input images. They use learnable filters (kernels) to convolve over the input, capturing local patterns, edges, textures, and other visual features. In AlexNet, the convolutional layers introduce non-linearity through the ReLU activation function. The specific roles of convolutional layers in AlexNet include:\n",
    "\n",
    "Feature Extraction: The convolutional layers act as local feature detectors, capturing low-level visual elements such as edges and corners.\n",
    "\n",
    "Hierarchical Representation: Each subsequent convolutional layer captures increasingly complex features by combining the features learned in the previous layers. This hierarchical representation helps the network recognize higher-level patterns.\n",
    "\n",
    "Spatial Preservation: While each convolutional layer reduces the spatial dimensions of the feature maps, they still maintain the spatial relationships between features. This is important for preserving local information.\n",
    "\n",
    "* Pooling Layers:\n",
    "Pooling layers downsample the feature maps obtained from the convolutional layers, reducing their spatial dimensions. This reduction helps retain the most important information while decreasing computational complexity. In AlexNet, max pooling layers with overlapping windows are used. The roles of pooling layers include:\n",
    "\n",
    "Dimension Reduction: Pooling layers reduce the spatial dimensions of the feature maps, making subsequent layers computationally more efficient and preventing overfitting.\n",
    "\n",
    "Feature Selection: By selecting the maximum (or average) value within each pooling region, pooling layers emphasize the most significant features while downplaying less important details.\n",
    "\n",
    "Translation Invariance: Max pooling, in particular, provides a degree of translation invariance by focusing on the most prominent features within a region, regardless of their exact positions.\n",
    "\n",
    "* Fully Connected Layers:\n",
    "Fully connected layers process the high-level features extracted by the convolutional and pooling layers and make final predictions for image classification. In AlexNet, fully connected layers use the ReLU activation function and dropout regularization. The roles of fully connected layers include:\n",
    "\n",
    "Integration of Features: Fully connected layers aggregate the high-level features captured by the previous layers to form a global representation of the input image.\n",
    "\n",
    "Non-linearity and Decision-Making: The ReLU activation introduces non-linearity, allowing the network to learn complex relationships in the data. The final fully connected layer with softmax activation produces class probabilities for image classification.\n",
    "\n",
    "Regularization: Dropout regularization is applied to fully connected layers to prevent overfitting. Dropout randomly deactivates a fraction of neurons during training, encouraging the network to learn more robust features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f5c76-d7f9-4c90-904b-04d0f49fa5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement AlexNet using a deep learning network of your choice and evaluate its performance a dataset of youc choice.\n",
    "!pip install tflearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# Get Data\n",
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "x, y = oxflower17.load_data()\n",
    "\n",
    "x_train = x.astype('float32') / 255.0\n",
    "y_train = to_categorical(y, num_classes=17)\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(17))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
