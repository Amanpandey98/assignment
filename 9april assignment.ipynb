{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca77b03-b633-41e7-8634-66bdcebbffd7",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e218d-708d-410b-b9f2-b9e8e26a3676",
   "metadata": {},
   "source": [
    "Bayes' theorem is used to update the probability of a hypothesis (a statement or assumption about the world) given new evidence or data. The theorem states that the probability of a hypothesis H given evidence E is proportional to the product of the probability of the evidence given the hypothesis, P(E|H), and the prior probability of the hypothesis, P(H), divided by the probability of the evidence, P(E):\n",
    "\n",
    "P(H|E) = P(E|H) * P(H) / P(E)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(H|E) is the posterior probability of the hypothesis given the evidence\n",
    "P(E|H) is the likelihood of the evidence given the hypothesis\n",
    "P(H) is the prior probability of the hypothesis\n",
    "P(E) is the probability of the evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c948187-a99c-4cdb-986a-f8656cc8e87a",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d6755-7a02-4a63-95bc-fbb11620fe9d",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(H|E) = P(E|H) * P(H) / P(E)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(H|E) is the posterior probability of the hypothesis given the evidence\n",
    "P(E|H) is the likelihood of the evidence given the hypothesis\n",
    "P(H) is the prior probability of the hypothesis\n",
    "P(E) is the probability of the evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4b6eb-0a3d-4950-bc8b-efea47808363",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c017c6-b5e4-4618-ae85-94dd40afebcc",
   "metadata": {},
   "source": [
    "Medical diagnosis: Bayes' theorem can be used to calculate the probability that a patient has a particular disease based on their symptoms, medical history, and other relevant information. The prior probability of the disease is updated based on the results of medical tests, allowing doctors to make more accurate diagnoses.\n",
    "\n",
    "Spam filtering: Bayesian spam filters use Bayes' theorem to calculate the probability that an incoming email is spam based on its content and other features. The prior probability of an email being spam is updated based on the occurrence of certain words or phrases in the email, allowing the filter to learn and adapt over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7383f86-8c61-472c-af2d-f19db6aa799e",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cdb8e3-b0dc-4ebc-81af-bebdb1de6a44",
   "metadata": {},
   "source": [
    "Bayes' theorem and conditional probability are closely related concepts. Conditional probability is the probability of an event occurring given that another event has occurred. Bayes' theorem is a formula that relates conditional probability to prior probabilities.\n",
    "\n",
    "In other words, Bayes' theorem provides a way to calculate the probability of a hypothesis given new evidence, by multiplying the likelihood of the evidence given the hypothesis by the prior probability of the hypothesis, and dividing by the probability of the evidence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ab176-6ccd-4aa5-8d73-f77910225424",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b839e0-95b3-4cd7-bd5a-cf6627a8b943",
   "metadata": {},
   "source": [
    "1. Gaussian Naive Bayes: This classifier is suitable for problems where the features are continuous and have a Gaussian distribution. It works well for problems such as image recognition or document classification, where the features are real-valued and represent some measurable quantity.\n",
    "\n",
    "2. Multinomial Naive Bayes: This classifier is suitable for problems where the features represent counts or frequencies, such as text classification or sentiment analysis. It works well for problems where the features are discrete and non-negative, and where the order of the words in the text is not important.\n",
    "\n",
    "3. Bernoulli Naive Bayes: This classifier is similar to the Multinomial Naive Bayes, but it is suitable for problems where the features are binary or Boolean, such as spam filtering or fraud detection. It works well for problems where the features represent the presence or absence of a certain attribute, and where the order of the attributes does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adba49d-ed14-4dd0-8b0f-93116558b48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551efa3e-fcaa-44bb-aa8a-a111ad9c7528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
